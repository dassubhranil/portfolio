<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>Generative AI for Pathology Datasets — Subhranil Das</title>
    <meta name="description" content="A research project exploring GANs in medical imaging, focusing on synthesizing pathology datasets for nuclei detection and model training." />

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700;800&display=swap" rel="stylesheet">
    <script src="https://cdn.tailwindcss.com"></script>

    <style>
        :root { --header-offset: 72px; }

/* ensure sections and titles leave room for fixed header when scrolled to */
section,
.section-title {
  scroll-margin-top: var(--header-offset);
}

/* smaller offset on small screens (optional) */
@media (max-width: 640px) {
  :root { --header-offset: 56px; }
}
        html { scroll-behavior: smooth; } /* Enable smooth scrolling */
        :root { --bg: #050816; --muted: #9ca3af; --glass-border: rgba(255,255,255,0.04); }
        html,body { height:100%; }
        body { font-family: 'Inter', sans-serif; background: radial-gradient(circle at 20% 20%, rgba(79,70,229,0.12), transparent 40%), radial-gradient(circle at 80% 80%, rgba(236,72,153,0.10), transparent 40%), var(--bg); color: #eef2ff; margin:0 }

        header .nav-link { position: relative; display: inline-block; text-decoration: none; }
        header .nav-link::after { content: ''; position: absolute; bottom: -6px; left: 0; width: 0; height: 2px; background: linear-gradient(90deg, #6366f1, #ec4899); transition: width 0.35s ease-in-out; }
        header .nav-link:hover::after { width: 100%; }

        .glass { backdrop-filter: blur(10px); background: linear-gradient(135deg, rgba(255,255,255,0.03), rgba(255,255,255,0.02)); border: 1px solid var(--glass-border); }
        .gradient-text { background: linear-gradient(90deg,#6366f1,#ec4899); -webkit-background-clip:text; background-clip:text; color:transparent; }
        .btn { background:linear-gradient(90deg,#6366f1,#ec4899);color:#fff;padding:10px 14px;border-radius:10px;text-decoration:none;display:inline-flex;align-items:center;gap:8px }
        .container { max-width:1100px; margin:0 auto; padding:36px }
        img { max-width:100%; display:block; border-radius:12px; }
        .kpi { font-weight:700; font-size:1.15rem; }
        .muted { color:var(--muted); }

        /* Reveal & cascade */
        .reveal { opacity: 0; transform: translateY(24px); transition: opacity 600ms cubic-bezier(.2,.9,.2,1), transform 600ms cubic-bezier(.2,.9,.2,1); }
        .reveal.show { opacity: 1; transform: translateY(0); }
        .cascade-item { opacity: 0; transform: translateY(8px); transition: opacity 480ms ease, transform 480ms ease; }
        .cascade-item.show { opacity: 1; transform: translateY(0); }

        /* Responsive section title smaller on mobile */
        .section-title { font-size:48px; margin:28px 0 16px; font-weight:800; line-height:1.05; }
        @media (max-width:640px){ .section-title{ font-size:28px; margin:18px 0 12px } .container{ padding:20px } }

        /* Card */
        .card { background: linear-gradient(180deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01)); border:1px solid var(--glass-border); padding:18px; border-radius:12px }

        /* subtle code block */
        pre.code { background: rgba(0,0,0,0.25); padding:12px; border-radius:8px; overflow:auto; }

        .toc a { color: #cbd5e1; text-decoration: none; }
        .toc a:hover { text-decoration: underline; color: #fff; }
    </style>
</head>
<body class="antialiased">
<header class="sticky top-0 z-50 bg-[#050816]/80 backdrop-blur-md border-b border-white/5">
    <div class="container flex items-center justify-between py-4">
        <a href="index.html#hero" class="text-xl font-extrabold gradient-text">Subhranil Das</a>

        <button id="mobile-menu-btn" class="md:hidden p-2 rounded-md focus:outline-none focus:ring-2 focus:ring-inset focus:ring-white/5" onclick="toggleMobileMenu()">
            <svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16m-7 6h7"></path>
            </svg>
        </button>

        <nav class="hidden md:flex flex-row items-center gap-6 text-sm text-gray-300">
            <div class="relative group py-2">
                <a class="nav-link px-3" href="index.html#about">About</a>
                <div class="absolute hidden group-hover:block bg-[#050816]/90 backdrop-blur-md border border-white/5 rounded-md mt-2 w-max shadow-lg z-10">
                    <a href="about.html" class="block px-4 py-2 text-gray-300 hover:bg-white/10 rounded-md whitespace-nowrap">Learn more about me</a>
                </div>
            </div>
<div class="relative group py-2">
  <a class="nav-link px-3 py-2 inline-flex items-center" href="index.html#projects" aria-haspopup="true" aria-expanded="false">
    Projects
  </a>

  <div class="absolute hidden group-hover:block bg-[#050816]/90 backdrop-blur-md border border-white/5 rounded-md mt-2 w-68 shadow-lg z-10">
    <a href="project1.html" class="block px-4 py-2 text-gray-300 hover:bg-white/10 rounded-md whitespace-nowrap">Generative AI for pathology Datasets</a>
    <a href="project3.html" class="block px-4 py-2 text-gray-300 hover:bg-white/10 rounded-md whitespace-nowrap">Dynamic Commentary Analytics</a>
    <a href="project4.html" class="block px-4 py-2 text-gray-300 hover:bg-white/10 rounded-md whitespace-nowrap">Heart Disease Prediction App</a>
    <a href="project2.html" class="block px-4 py-2 text-gray-300 hover:bg-white/10 rounded-md whitespace-nowrap">Turbocharging-Retail-Insights</a>
  </div>
</div>
            <a class="nav-link px-3 py-2" href="index.html#skills">Skills</a>
            <a class="nav-link px-3 py-2" href="index.html#tools">Tools</a>
            <a class="nav-link px-3 py-2" href="index.html#contact">Contact</a>
            
            <div class="relative group py-2">
                <a class="nav-link px-3" href="#">Social</a>
                <div class="absolute hidden group-hover:block bg-[#050816]/90 backdrop-blur-md border border-white/5 rounded-md mt-2 w-max shadow-lg z-10">
                    <a href="https://www.linkedin.com/in/subhranil-das" target="_blank" class="block px-4 py-2 text-gray-300 hover:bg-white/10 rounded-md whitespace-nowrap">LinkedIn</a>
                    <a href="https://github.com/dassubhranil" target="_blank" class="block px-4 py-2 text-gray-300 hover:bg-white/10 rounded-md whitespace-nowrap">GitHub</a>
                </div>
            </div>
        </nav>
    </div>
</header>

<div id="mobile-menu" class="fixed top-0 left-0 w-full h-full bg-[#050816]/90 backdrop-blur-md transform -translate-x-full transition-transform duration-300 z-50 p-6 md:hidden">
    <div class="flex justify-end">
        <button id="close-menu-btn" class="p-2 rounded-md focus:outline-none focus:ring-2 focus:ring-inset focus:ring-white/5" onclick="toggleMobileMenu()">
            <svg class="w-6 h-6 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path>
            </svg>
        </button>
    </div>
    <nav class="flex flex-col gap-4 text-xl mt-8">
        <div class="relative">
            <a class="nav-link text-white" href="index.html#about" onclick="toggleMobileMenu()">About</a>
            <div class="flex flex-col gap-2 pl-4 mt-2">
                <a href="about.html" class="block px-2 text-gray-400 hover:text-white" onclick="toggleMobileMenu()">Learn more about me</a>
            </div>
        </div>
<div>
  <a class="nav-link text-white" href="index.html#projects" onclick="toggleMobileMenu(); smoothScrollTo('projects');">
    Projects
  </a>

  <div class="flex flex-col gap-2 pl-4 mt-2">
    <a href="project1.html" class="block text-gray-400 hover:text-white" onclick="toggleMobileMenu()">Generative AI for pathology Datasets</a>
    <a href="project3.html" class="block text-gray-400 hover:text-white" onclick="toggleMobileMenu()">Dynamic Commentary Analytics</a>
    <a href="project4.html" class="block text-gray-400 hover:text-white" onclick="toggleMobileMenu()">Heart Disease Prediction App</a>
    <a href="project2.html" class="block text-gray-400 hover:text-white" onclick="toggleMobileMenu()">Turbocharging-Retail-Insights</a>
  </div>
</div>
<a class="nav-link text-white" href="index.html#skills" onclick="toggleMobileMenu()">Skills</a>
        <a class="nav-link text-white" href="index.html#tools" onclick="toggleMobileMenu()">Tools</a>
        <a class="nav-link text-white" href="index.html#contact" onclick="toggleMobileMenu()">Contact</a>
        
        <div class="relative">
            <a class="nav-link text-white" href="#" onclick="toggleMobileMenu()">Social</a>
            <div class="flex flex-col gap-2 pl-4 mt-2">
                <a href="https://www.linkedin.com/in/subhranil-das" target="_blank" class="block px-2 text-gray-400 hover:text-white" onclick="toggleMobileMenu()">LinkedIn</a>
                <a href="https://github.com/dassubhranil" target="_blank" class="block px-2 text-gray-400 hover:text-white" onclick="toggleMobileMenu()">GitHub</a>
            </div>
        </div>
    </nav>
</div>


    <main class="container pt-28">
        <section id="hero" class="reveal glass p-8 rounded-xl">
            <div class="flex flex-col md:flex-row md:items-center gap-8">
                <div class="flex-1">
                    <h1 class="section-title gradient-text cascade-item">Generative AI for Pathology Datasets</h1>
                    <p class="muted mb-4 cascade-item">Research project exploring the use of generative models to synthesize pathology image data and improve nuclei detection models while preserving patient privacy.</p>

                    <div class="flex gap-3 items-center mb-6 cascade-item">
                        <div class="card p-4">
                            <div class="muted">Project type</div>
                            <div class="kpi">Research • Medical Imaging</div>
                        </div>
                        <div class="card p-4">
                            <div class="muted">Technologies</div>
                            <div class="kpi"><strong class="gradient-text">GANs</strong> • <strong class="gradient-text">StyleGAN3</strong> • <strong class="gradient-text">YOLOv8</strong> • PyTorch</div>
                        </div>
                        <div class="card p-4">
                            <div class="muted">Impact</div>
                            <div class="kpi"><strong class="gradient-text">+40% (relative)</strong> • Accuracy <strong class="gradient-text">85%</strong></div>
                        </div>
                        <div class="flex gap-3 justify-center items-center mb-6 cascade-item">
                <a href="https://github.com/dassubhranil/Generative-AI-for-Pathology-Datasets" class="btn" target="_blank">Repo</a>
            </div>
                    </div>

                    <p class="cascade-item">This page documents the problem, approach, experiments, and results. It is intended for technical readers who want reproducible details and for hiring managers who want an accessible summary.</p>
                </div>

                <div class="w-full md:w-5/12 cascade-item">
                    <img src="Real.png" alt="Pathology sample" class="rounded-xl shadow-lg">
                </div>
            </div>
        </section>

        <section id="overview" class="py-8">
            <div class="glass p-6 rounded-xl reveal">
                <h2 class="text-2xl font-semibold mb-3">Project Overview</h2>
                <p class="text-gray-300 mb-3">Medical imaging datasets—especially histopathology slides—are sensitive and hard to share. This project investigates whether state-of-the-art generative models can produce <strong class="gradient-text">synthetic datasets</strong> that retain biological signal and are useful for downstream tasks like <strong class="gradient-text">nuclei detection</strong>.</p>

                <h3 class="mt-4 text-lg font-semibold">Goals</h3>
                <ul class="list-disc list-inside text-gray-300 space-y-2 mb-4">
                    <li>Create high-fidelity <strong class="gradient-text">synthetic pathology images</strong> that preserve key biological features.</li>
                    <li>Train detection models on synthetic data and measure transfer performance to <strong class="gradient-text">real data</strong>.</li>
                    <li>Open-source tooling and reproducible pipelines for research and clinical collaboration.</li>
                </ul>

                <h3 class="mt-4 text-lg font-semibold">Challenges</h3>
                <ul class="list-disc list-inside text-gray-300 space-y-2">
                    <li>Balancing realism with <strong class="gradient-text">privacy</strong>—avoid leaking patient-identifiable artifacts.</li>
                    <li>Mode collapse and training instability common in <strong class="gradient-text">GANs</strong>.</li>
                    <li>Quantitatively evaluating synthetic data quality for biological tasks.</li>
                </ul>
            </div>
        </section>

        <section id="methods" class="py-8">
            <div class="glass p-6 rounded-xl reveal">
                <h2 class="text-2xl font-semibold mb-4">Methods</h2>

                <h3 class="text-lg font-semibold mb-2">Data Preparation</h3>
                <p class="text-gray-300 mb-3">Clinical samples were preprocessed to standardize staining and tile sizes. Annotation masks for nuclei were created using a combination of semi-automated segmentation (watershed + U-Net prototypes) and expert correction. Data augmentation included color normalization, rotation, and elastic transforms to improve robustness.</p>

                <h3 class="text-lg font-semibold mb-2">Generative Models</h3>
                <p class="text-gray-300 mb-3">We experimented with multiple generative families:</p>
                <ul class="list-disc list-inside text-gray-300 space-y-2 mb-4">
                    <li><strong class="gradient-text">DCGAN</strong> — baseline generative model for image synthesis.</li>
                    <li><strong class="gradient-text">Variational Autoencoders (VAE)</strong> — for controllable latent-space sampling and measuring reconstruction fidelity.</li>
                    <li><strong class="gradient-text">StyleGAN3</strong> — produced the highest-fidelity patches; enabled style mixing to vary staining and scanner characteristics.</li>
                </ul>

                <h3 class="text-lg font-semibold mb-2">Downstream Model</h3>
                <p class="text-gray-300 mb-3">We trained a <strong class="gradient-text">YOLOv8</strong>-based nuclei detector on synthetic datasets and evaluated it on held-out real-world test sets. Training leveraged <strong class="gradient-text">mixed precision</strong>, staged curriculum learning (from small to larger tiles), and a synthetic pretrain → small real fine-tune schedule.</p>

                <h3 class="text-lg font-semibold mb-2">Evaluation Metrics</h3>
                <p class="text-gray-300 mb-2">We used multiple quantitative and qualitative measures:</p>
                <ul class="list-disc list-inside text-gray-300 space-y-2">
                    <li><strong class="gradient-text">Detection mAP</strong> on real test sets (primary metric).</li>
                    <li><strong class="gradient-text">Fréchet Inception Distance (FID)</strong> to assess visual fidelity of synthetic images.</li>
                    <li><strong class="gradient-text">Biological feature agreement</strong> — distribution of nucleus sizes, intensities, and texture features compared between real and synthetic sets (Kolmogorov–Smirnov tests).</li>
                </ul>
            </div>
        </section>

        <section id="experiments" class="py-8">
            <div class="glass p-6 rounded-xl reveal">
                <h2 class="text-2xl font-semibold mb-4">Experiments</h2>

                <h3 class="text-lg font-semibold mb-2">Training setup</h3>
                <p class="text-gray-300 mb-3">Experiments were run on NVIDIA GPUs (3090/A100). <strong class="gradient-text">StyleGAN3</strong> training used progressive resolution up to <strong class="gradient-text">256×256</strong> tiles for diverse cellular structures. Batch sizes and learning rates were tuned per model; best configs are in the repo's config files.</p>

                <h3 class="text-lg font-semibold mb-2">Ablation studies</h3>
                <ul class="list-disc list-inside text-gray-300 space-y-2">
                    <li><strong class="gradient-text">Style mixing</strong> off vs on — assessed effect on downstream <strong class="gradient-text">mAP</strong>.</li>
                    <li><strong class="gradient-text">GAN loss</strong> variants (non-saturating, hinge) compared for stability and <strong class="gradient-text">FID</strong>.</li>
                    <li>Amount of <strong class="gradient-text">synthetic pretraining</strong> (ratio synthetic:real) tested to find sweet spot for fine-tuning.</li>
                </ul>

                <h3 class="text-lg font-semibold mb-2">Human-in-loop refinement</h3>
                <p class="text-gray-300 mb-3">Domain experts reviewed synthesized patches and annotated obviously unrealistic artifacts; flagged patches were filtered and used to augment the discriminator's training set to reduce memorization of anomalous artifacts. This <strong class="gradient-text">human-in-loop</strong> step significantly improved clinical plausibility.</p>
            </div>
        </section>

        <section id="results" class="py-8">
            <div class="glass p-6 rounded-xl reveal">
                <h2 class="text-2xl font-semibold mb-4">Results</h2>

                <div class="grid md:grid-cols-3 gap-4 mb-6">
                  <div class="card">
                    <div class="muted">Model improvement</div>
                    <div class="kpi"><strong class="gradient-text">+40% (relative)</strong></div>
                    <div class="text-sm muted mt-2">Measured as relative increase in <strong class="gradient-text">mAP</strong> when training with <strong class="gradient-text">synthetic + real</strong> vs real-only (controlled experiment).</div>
                  </div>
                  <div class="card">
                    <div class="muted">Detection accuracy</div>
                    <div class="kpi"><strong class="gradient-text">85%</strong> (YOLOv8 on real test set)</div>
                    <div class="text-sm muted mt-2">Best model trained on synthetic data then fine-tuned on a small real set.</div>
                  </div>
                  <div class="card">
                    <div class="muted">FID (StyleGAN3)</div>
                    <div class="kpi"><strong class="gradient-text">~18</strong> (lower is better)</div>
                    <div class="text-sm muted mt-2">Indicative of high visual fidelity for microscopy patches.</div>
                  </div>
                </div>

                <h3 class="text-lg font-semibold mb-2">Visual Examples</h3>
                <div class="grid md:grid-cols-2 gap-4 mb-4">
                    <img src="Real.png" alt="Real sample 1">
                    <img src="Synthetic.png" alt="Synthetic sample 1">
                </div>

                <h3 class="text-lg font-semibold mb-2">Ablation & Sensitivity</h3>
                <p class="text-gray-300 mb-3">We ablated components such as: <strong class="gradient-text">style augmentation</strong>, <strong class="gradient-text">GAN loss variants</strong>, and <strong class="gradient-text">progressive training</strong> schedule. Removing style mixing reduced downstream <strong class="gradient-text">mAP</strong> by ~9% in our experiments.</p>

                <h3 class="text-lg font-semibold mb-2">Privacy & Memorization Checks</h3>
                <p class="text-gray-300 mb-3">We applied <strong class="gradient-text">nearest-neighbor</strong> checks in deep feature space, p-hacking resistance measures, and manual inspection by pathologists to ensure generators did not reproduce identifiable patient patches. Any patch with a near-identical real neighbor was removed from provided synthetic releases.</p>
            </div>
        </section>

        <section id="analysis" class="py-8">
          <div class="glass p-6 rounded-xl reveal">
            <h2 class="text-2xl font-semibold mb-4">Quantitative Analysis</h2>
            <p class="text-gray-300 mb-3">Key statistical checks and visual scores used to validate synthetic data:</p>
            <ul class="list-disc list-inside text-gray-300 space-y-2">
              <li>Comparative distributions (size, intensity) with <strong class="gradient-text">KS test</strong> p-values reported in the repo.</li>
              <li>Detection performance curves (<strong class="gradient-text">precision/recall</strong>) showing gains from synthetic pretraining.</li>
              <li><strong class="gradient-text">FID</strong> and Inception scores tracked per checkpoint; early stopping used when overfitting signs appeared.</li>
            </ul>
          </div>
        </section>

        <section id="repro" class="py-8">
            <div class="glass p-6 rounded-xl reveal">
                <h2 class="text-2xl font-semibold mb-4">Reproducibility & Code</h2>
                <p class="text-gray-300 mb-3">All code, data-processing notebooks, and model checkpoints are available in the public repository. Below are quick pointers to reproduce core experiments locally or on a GPU cloud instance.</p>

                <h3 class="text-lg font-semibold mb-2">Quick start (local)</h3>
                <pre class="code"># clone repo
git clone https://github.com/dassubhranil/pathology-gan-project.git
cd pathology-gan-project
# create environment
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
# run training (example)
python train_stylegan3.py --config=configs/tiles.yaml --gpus=1
                </pre>

                <h3 class="text-lg font-semibold mb-2">Notebooks & checkpoints</h3>
                <ul class="list-disc list-inside text-gray-300 space-y-2">
                    <li>Notebooks for preprocessing, augmentation, model training and evaluation.</li>
                    <li>Pretrained checkpoints (<strong class="gradient-text">StyleGAN3</strong>) for quick sampling and evaluation are pushed to the repo release section.</li>
                </ul>

                <h3 class="text-lg font-semibold mb-2">Environment & Hardware</h3>
                <p class="text-gray-300 mb-3">Recommended: NVIDIA GPUs (A100/3090/2080Ti), 16–64GB VRAM depending on tile size. We used <strong class="gradient-text">mixed precision</strong> training & distributed sampling for larger models.</p>
            </div>
        </section>

        <section id="appendix" class="py-8">
          <div class="glass p-6 rounded-xl reveal">
            <h2 class="text-2xl font-semibold mb-4">Appendix — Additional details</h2>
            <h3 class="text-lg font-semibold mb-2">Configuration highlights</h3>
            <ul class="list-disc list-inside text-gray-300 space-y-2 mb-3">
              <li><strong class="gradient-text">StyleGAN3</strong> configs: tile size 128→256, RAdam optimizer for certain runs, spectral regularization experiments included.</li>
              <li><strong class="gradient-text">YOLOv8</strong> training: mosaic augmentation disabled for certain ablations; IoU thresholds tuned for nuclei scale.</li>
            </ul>

            <h3 class="text-lg font-semibold mb-2">Human review notes</h3>
            <p class="text-gray-300 mb-3">Expert pathologist flagged roughly ~7% of generated patches as clinically implausible in early iterations; after targeted retraining this dropped below 2% for <strong class="gradient-text">StyleGAN3</strong> outputs.</p>
          </div>
        </section>

    <footer class="reveal py-8">
      <div class="container">
        <div class="card cascade-item p-6 rounded-xl flex flex-col md:flex-row items-center justify-between gap-6">
          <div class="flex items-center gap-4">
            <a href="https://www.linkedin.com/in/subhranil-das" target="_blank" rel="noopener noreferrer" class="text-gray-300 hover:text-white inline-flex items-center gap-2">
              <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linkedin/linkedin-original.svg" alt="LinkedIn" class="social-icon" style="width:20px;height:20px;" onerror="this.onerror=null;this.src='https://placehold.co/20x20/111827/e5e7eb?text=IN'"/>
              LinkedIn
            </a>
            <a href="https://github.com/dassubhranil" target="_blank" rel="noopener noreferrer" class="text-gray-300 hover:text-white inline-flex items-center gap-2">
              <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" alt="GitHub" class="social-icon" style="width:20px;height:20px;" onerror="this.onerror=null;this.src='https://placehold.co/20x20/111827/e5e7eb?text=GH'"/>
              GitHub
            </a>
          </div>
          <div style="color:#9ca3af;font-size:13px">© <span id="year"></span> Subhranil Das • Built with passion.</div>
        </div>
      </div>
    </footer>
        </main>

<!-- ===== Add this small JS near the end of <body> (once) ===== -->
<!-- ===== Add this JS once (near end of <body>) ===== -->
<script>
  (function () {
    const openBtn = document.getElementById('mobileOpenBtn');
    const mobileMenu = document.getElementById('mobileMenu');
    const hamburger = document.getElementById('hamburger');
    const closeIcon = document.getElementById('closeIcon');

    if (!openBtn || !mobileMenu) return;

    openBtn.addEventListener('click', () => {
      const isHidden = mobileMenu.classList.toggle('hidden');
      // toggle icons (hamburger vs close)
      hamburger.classList.toggle('hidden', !isHidden); // show hamburger when hidden==true
      closeIcon.classList.toggle('hidden', isHidden);
      // update aria
      const expanded = openBtn.getAttribute('aria-expanded') === 'true';
      openBtn.setAttribute('aria-expanded', (!expanded).toString());
    });

    // close mobile menu when clicking any link inside it
    mobileMenu.querySelectorAll('a').forEach(a => {
      a.addEventListener('click', () => {
        if (!mobileMenu.classList.contains('hidden')) {
          mobileMenu.classList.add('hidden');
          hamburger.classList.remove('hidden');
          closeIcon.classList.add('hidden');
          openBtn.setAttribute('aria-expanded', 'false');
        }
      });
    });
  })();
</script>
    <script>
      document.getElementById('year').textContent = new Date().getFullYear();

      // ===== Reveal logic for this page =====
      const revealSections = document.querySelectorAll('.reveal');
      const revealObserver = new IntersectionObserver((entries, obs) => {
        entries.forEach(entry => {
          if(entry.isIntersecting){
            const sec = entry.target;
            sec.classList.add('show');
            const children = sec.querySelectorAll('.cascade-item');
            children.forEach((c, idx) => {
              c.style.transitionDelay = (idx * 80) + 'ms';
              requestAnimationFrame(() => c.classList.add('show'));
            });
            obs.unobserve(sec);
          }
        });
      }, { threshold: 0.12 });
      revealSections.forEach((s,i) => { s.style.transitionDelay = (i * 80) + 'ms'; revealObserver.observe(s); });
    </script>
    <script>
  // Compute header height and set CSS variable so scroll offset matches actual header size.
  function updateHeaderOffset() {
    const header = document.querySelector('header');
    if (!header) return;
    // add a small extra gap (12px) so title isn't flush against header
    const offset = Math.ceil(header.getBoundingClientRect().height) + 12;
    document.documentElement.style.setProperty('--header-offset', offset + 'px');
  }

  window.addEventListener('load', updateHeaderOffset);
  window.addEventListener('resize', updateHeaderOffset);
  // run once in case DOM already loaded
  updateHeaderOffset();
  function toggleMobileMenu() {
    const mobileMenu = document.getElementById('mobile-menu');
    if (mobileMenu) {
        mobileMenu.classList.toggle('-translate-x-full');
    }
}
</script>
</body>
</html>
